{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary prediction, episode II: make it actually work (4 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know the drill :)\n",
    "\n",
    "You can use either __pytorch__ or __tensorflow__ or any other framework (e.g. pure __keras__). Feel free to adapt the seminar code for your needs. For tensorflow version, consider `seminar_tf2.ipynb` as a starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"D:\\Яндекс_Практикум\\ШАД\\NLP_Course\\video\\2_week\\Train_rev1.zip\", compression='zip', index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25000, 30000, 27500, ..., 32494, 26040, 37804], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.SalaryNormalized.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199553</th>\n",
       "      <td>71851249</td>\n",
       "      <td>CPCS Roller Driver</td>\n",
       "      <td>We urgently require CPCS Roller Drivers to wor...</td>\n",
       "      <td>Southminster Essex South East</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>Gold Group Ltd.</td>\n",
       "      <td>Trade &amp; Construction Jobs</td>\n",
       "      <td>10 - 11 per hour</td>\n",
       "      <td>20160</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>9.911506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204535</th>\n",
       "      <td>72033578</td>\n",
       "      <td>Guaranteed Primary Teacher workEaling and Brent</td>\n",
       "      <td>Guaranteed Primary Teacher Work  Ealing &amp; Bren...</td>\n",
       "      <td>Central London</td>\n",
       "      <td>Central London</td>\n",
       "      <td>full_time</td>\n",
       "      <td>contract</td>\n",
       "      <td>ITN Mark Education West London</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>30000.00 - 42500.00 GBP Annual</td>\n",
       "      <td>36250</td>\n",
       "      <td>jobs.newstatesman.com</td>\n",
       "      <td>10.498222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78002</th>\n",
       "      <td>69013272</td>\n",
       "      <td>Warehouse Manager</td>\n",
       "      <td>An excellent opportunity has become available ...</td>\n",
       "      <td>Bromsgrove, Hereford Worcestershire</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>Adecco</td>\n",
       "      <td>Other/General Jobs</td>\n",
       "      <td>16000 - 17000/annum</td>\n",
       "      <td>16500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>9.711176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                            Title  \\\n",
       "199553  71851249                               CPCS Roller Driver   \n",
       "204535  72033578  Guaranteed Primary Teacher workEaling and Brent   \n",
       "78002   69013272                                Warehouse Manager   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "199553  We urgently require CPCS Roller Drivers to wor...   \n",
       "204535  Guaranteed Primary Teacher Work  Ealing & Bren...   \n",
       "78002   An excellent opportunity has become available ...   \n",
       "\n",
       "                                LocationRaw LocationNormalized ContractType  \\\n",
       "199553        Southminster Essex South East                 UK          NaN   \n",
       "204535                       Central London     Central London    full_time   \n",
       "78002   Bromsgrove, Hereford Worcestershire                 UK          NaN   \n",
       "\n",
       "       ContractTime                         Company  \\\n",
       "199553     contract                 Gold Group Ltd.   \n",
       "204535     contract  ITN Mark Education West London   \n",
       "78002      contract                          Adecco   \n",
       "\n",
       "                         Category                       SalaryRaw  \\\n",
       "199553  Trade & Construction Jobs                10 - 11 per hour   \n",
       "204535              Teaching Jobs  30000.00 - 42500.00 GBP Annual   \n",
       "78002          Other/General Jobs             16000 - 17000/annum   \n",
       "\n",
       "        SalaryNormalized             SourceName  Log1pSalary  \n",
       "199553             20160          totaljobs.com     9.911506  \n",
       "204535             36250  jobs.newstatesman.com    10.498222  \n",
       "78002              16500       cv-library.co.uk     9.711176  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def _tokenize(text:str) -> str:\n",
    "    text = str(text)\n",
    "    return ' '.join(tokenizer.tokenize(text)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"] = data[\"Title\"].apply(_tokenize)\n",
    "data[\"FullDescription\"] = data[\"FullDescription\"].apply(_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "for title in data['Title']:\n",
    "    for token in title.split():\n",
    "        token_counts[token] += 1 \n",
    "        \n",
    "for title in data['FullDescription']:\n",
    "    for token in title.split():\n",
    "        token_counts[token] += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = sorted(t for t, c in token_counts.items() if c >= min_count)#TODO<YOUR CODE HERE>\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(tokens))\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {}\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    token_to_id[token] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def to_tensors(batch, device):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        if key in [\"FullDescription\", \"Title\"]:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
    "        else:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
    "    return batch_tensors\n",
    "\n",
    "\n",
    "def make_batch(data, max_len=None, word_dropout=0, device=device):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "    \n",
    "    return to_tensors(batch, device)\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': tensor([[27645, 29893, 33674]], device='cuda:0'),\n",
       " 'FullDescription': tensor([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451, 32939]],\n",
       "        device='cuda:0'),\n",
       " 'Categorical': tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " 'Log1pSalary': tensor([9.7115], device='cuda:0')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:1], max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = make_batch(data_train, max_len=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(num_embeddings=len(tokens), embedding_dim=32)\n",
    "        self.conv = torch.nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3,)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        embs = self.emb(idx)\n",
    "        emb_transposed = torch.einsum('ijk->ikj', embs)\n",
    "        convs_outs = self.conv(emb_transposed)\n",
    "        max_pool = torch.max(convs_outs, dim=-1).values\n",
    "        return max_pool\n",
    "    \n",
    "\n",
    "class SalaryPredictionModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_tokens=len(tokens), \n",
    "                 n_cat_features=len(categorical_vectorizer.vocabulary_), \n",
    "                 hid_size=64):\n",
    "        super(SalaryPredictionModel, self).__init__()\n",
    "        \n",
    "        # Эмбеддинг слой для текстовых данных\n",
    "        self.emb = TextEncoder()\n",
    "\n",
    "        # Полносвязный слой для категориальных данных\n",
    "        self.fc_categ = nn.Linear(n_cat_features, hid_size)\n",
    "\n",
    "        # Объединение выходов\n",
    "        self.fc_combined = nn.Linear(3 * hid_size, 2 * hid_size)\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.fc_out = nn.Linear(2 * hid_size, 1)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "    def forward(self, title, descr, categ):\n",
    "        # Применение эмбеддинга и свертки к заголовку\n",
    "        title_out = self.emb(title)\n",
    "\n",
    "        # Применение эмбеддинга и свертки к описанию\n",
    "        descr_out = self.emb(descr)\n",
    "\n",
    "        # Применение полносвязного слоя к категориальным данным\n",
    "        categ_out = F.relu(self.fc_categ(categ))\n",
    "\n",
    "        # Объединение выходов\n",
    "        combined = torch.cat([title_out, descr_out, categ_out], dim=1)\n",
    "        combined = F.relu(self.fc_combined(combined))\n",
    "\n",
    "        # Выходной слой\n",
    "        out = self.fc_out(self.dropout(combined))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SalaryDataset(Dataset):\n",
    "    def __init__(self, titles, descriptions, categorical, salaries):\n",
    "        self.titles = titles\n",
    "        self.descriptions = descriptions\n",
    "        self.categorical = categorical\n",
    "        self.salaries = salaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.salaries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"Title\": self.titles[idx],\n",
    "            \"FullDescription\": self.descriptions[idx],\n",
    "            \"Categorical\": self.categorical[idx],\n",
    "            \"Log1pSalary\": self.salaries[idx]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Создание экземпляра Dataset\n",
    "dataset = SalaryDataset(b['Title'], b['FullDescription'], b['Categorical'], b['Log1pSalary'])\n",
    "\n",
    "# Создание DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=20, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictionModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss after 0 batches: 0.4074\n",
      "Average loss after 1000 batches: 0.4248\n",
      "Average loss after 2000 batches: 0.4240\n",
      "Average loss after 3000 batches: 0.4227\n",
      "Average loss after 4000 batches: 0.4210\n",
      "Average loss after 5000 batches: 0.4179\n",
      "Average loss after 6000 batches: 0.4154\n",
      "Average loss after 7000 batches: 0.4122\n",
      "Average loss after 8000 batches: 0.4095\n",
      "Average loss after 9000 batches: 0.4067\n",
      "Epoch [1/3], Loss: 0.4045\n",
      "Average loss after 0 batches: 0.3816\n",
      "Average loss after 1000 batches: 0.3742\n",
      "Average loss after 2000 batches: 0.3734\n",
      "Average loss after 3000 batches: 0.3713\n",
      "Average loss after 4000 batches: 0.3691\n",
      "Average loss after 5000 batches: 0.3667\n",
      "Average loss after 6000 batches: 0.3648\n",
      "Average loss after 7000 batches: 0.3628\n",
      "Average loss after 8000 batches: 0.3607\n",
      "Average loss after 9000 batches: 0.3585\n",
      "Epoch [2/3], Loss: 0.3565\n",
      "Average loss after 0 batches: 0.2891\n",
      "Average loss after 1000 batches: 0.3331\n",
      "Average loss after 2000 batches: 0.3285\n",
      "Average loss after 3000 batches: 0.3264\n",
      "Average loss after 4000 batches: 0.3247\n",
      "Average loss after 5000 batches: 0.3230\n",
      "Average loss after 6000 batches: 0.3208\n",
      "Average loss after 7000 batches: 0.3191\n",
      "Average loss after 8000 batches: 0.3168\n",
      "Average loss after 9000 batches: 0.3146\n",
      "Epoch [3/3], Loss: 0.3130\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        titles = batch['Title'].to(device)\n",
    "        descriptions = batch['FullDescription'].to(device)\n",
    "        categorical = batch['Categorical'].to(device)\n",
    "        salaries = batch['Log1pSalary'].to(device)\n",
    "\n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Прямое распространение\n",
    "        outputs = model(titles, descriptions, categorical)\n",
    "\n",
    "        # Расчет потерь\n",
    "        loss = criterion(outputs, salaries.unsqueeze(1))\n",
    "\n",
    "        # Обратное распространение и оптимизация\n",
    "        loss.backward()\n",
    "\n",
    "#         # Проверка и вывод градиентов (каждые 1000 итераций)\n",
    "#         if i % 5000 == 0:\n",
    "#             for name, param in model.emb.named_parameters():\n",
    "#                 if param.grad is not None:\n",
    "#                     print(f\"Gradient for {name}: {param.grad.norm()}\")\n",
    "#                     print()\n",
    "#                 else:\n",
    "#                     print('------------------------')\n",
    "#                     print(f\"NO gradient for {name}\")\n",
    "#                     print('========================')\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Average loss after {i} batches: {total_loss / (i + 1):.4f}')\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = make_batch(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.6454]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "single_title = test['Title'][0].unsqueeze(0)  # Добавляем размерность батча\n",
    "single_description = test['FullDescription'][0].unsqueeze(0)\n",
    "single_categorical = test['Categorical'][0].unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    single_prediction = model(single_title, single_description, single_categorical)\n",
    "\n",
    "print(single_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.6454]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[41995.875]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = test['Title'][0].unsqueeze(0) \n",
    "descr = test['FullDescription'][0].unsqueeze(0)\n",
    "categ = test['Categorical'][0].unsqueeze(0)\n",
    "\n",
    "\n",
    "# Предполагаем, что у вас есть данные: titles, descriptions, categorical\n",
    "titles = titles.to(device)  # Перенос на GPU, если используется\n",
    "descriptions = descriptions.to(device)\n",
    "categorical = categorical.to(device)\n",
    "\n",
    "model.eval()  # Переключение модели в режим оценки\n",
    "with torch.no_grad():\n",
    "    predictions = model(title, descr, categ)\n",
    "    print(predictions)\n",
    "# Преобразование предсказаний, если это необходимо\n",
    "# Например, если вы использовали log1p для метки, примените expm1\n",
    "predicted_salaries = torch.expm1(predictions).to('cpu').numpy()\n",
    "predicted_salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm*`/`L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time (independently for each feature)\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not download pre-trained embeddings from [here](http://nlp.stanford.edu/data/glove.6B.zip) and follow this [manual](https://keras.io/examples/nlp/pretrained_word_embeddings/) to initialize your Keras embedding layer with downloaded weights.\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback(keras)](https://keras.io/callbacks/#earlystopping) or in [pytorch(lightning)](https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv5",
   "language": "python",
   "name": "venv5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
